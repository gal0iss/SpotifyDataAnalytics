# ðŸŽµ Spotify Portfolio - AnÃ¡lisis e IngenierÃ­a de Datos

Proyecto de anÃ¡lisis de histÃ³rico de reproducciÃ³n de Spotify usando arquitectura simple de datos (ETL).

##  DescripciÃ³n

Pipeline de datos que procesa archivos JSON del historial de Spotify y genera:
- **Dimensiones**: fecha, dispositivo, track, episodio, ubicaciÃ³n
- **Tabla de Hechos**: eventos de reproducciÃ³n
- **Enriquecimiento**: geolocalizaciÃ³n de IPs (ciudad, ISP, coordenadas)

##  Estructura del Proyecto

```
portafolio-spotify/
â”œâ”€â”€ main.py                    #  Orquestador principal (START HERE)
â”œâ”€â”€ README.md                  # Este archivo
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   #  JSONs originales del exporto de Spotify
â”‚   â”œâ”€â”€ processed/             #  Archivos Parquet procesados
â”‚   â””â”€â”€ Databases/             #  Bases geogrÃ¡ficas MaxMind (GeoLite2)
â””â”€â”€ src/
    â”œâ”€â”€ ReadProcess.py         # Extract + Transform (dimensiones, hechos)
    â”œâ”€â”€ localization.py        # Enriquecimiento: geolocalizaciÃ³n de IPs
    â””â”€â”€ validate.py            # ValidaciÃ³n: calidad de datos
```

##  CÃ³mo usar

### 1. Preparar ambiente

```bash
# Crear entorno virtual (si no existe)
python -m venv .venv

# Activar
.venv\Scripts\Activate.ps1     # Windows PowerShell
source .venv/bin/activate      # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Ubicar datos

Coloca tus JSONs del historial de Spotify en `data/raw/`:
- `Streaming_History_Audio_YYYY-YYYY_X.json`

> Si trabajas con varias cuentas o quieres mantener directorios separados,
> define la variable de entorno `SPOTIFY_USER_SUFFIX` (ej. `Pedro`) antes de
> ejecutar el pipeline; el script ajustarÃ¡ automÃ¡ticamente `data/raw{suffix}`
> y `data/processed{suffix}`.

Nota: Requiere bases de datos GeoLite2 en `data/Databases/` (descargar de MaxMind)

### 3. Ejecutar pipeline

```bash
python main.py
```

El script ejecutarÃ¡ en orden:
1. **Extract & Transform** - Procesa JSONs y crea dimensiones
2. **Enrich** - Geolocaliza IPs (opcional - requiere GeoLite2)
3. **Validate** - Verifica calidad de datos

## Salidas

Archivos Parquet en `data/processed/`:

| Archivo | DescripciÃ³n |
|---------|-------------|
| `dim_date.parquet` | DimensiÃ³n temporal (aÃ±o, mes, dÃ­a, hora, dÃ­a semana) |
| `dim_device.parquet` | Dispositivos (mÃ³vil, desktop, web) |
| `dim_track.parquet` | Tracks (URI, nombre, artista, Ã¡lbum) |
| `dim_episode.parquet` | Episodios de podcasts |
| `dim_location.parquet` | UbicaciÃ³n (IP, paÃ­s) |
| `dim_location_enriched.parquet` | UbicaciÃ³n enriquecida (ciudad, ISP, lat/lon) |
| `fact_table.parquet` | Tabla de hechos (reproduciones) |

## ï¿½ Archivos de registro

Los mensajes del pipeline se envÃ­an tanto a la consola como a un fichero de
texto dentro de la carpeta `logs/` (se crea automÃ¡ticamente). Revisa los logs
para diagnosticar errores o verificar pasos intermedios.

## MÃ©trica Principal

Tabla de hechos estructura tipo **Star Schema**:

```
fact_table
â”œâ”€â”€ event_id (PK)
â”œâ”€â”€ date_id (FK â†’ dim_date)
â”œâ”€â”€ track_id (FK â†’ dim_track)
â”œâ”€â”€ episode_id (FK â†’ dim_episode)
â”œâ”€â”€ device_id (FK â†’ dim_device)
â”œâ”€â”€ location_id (FK â†’ dim_location)
â”œâ”€â”€ ms_played
â”œâ”€â”€ skipped
â”œâ”€â”€ shuffle
â”œâ”€â”€ offline
â””â”€â”€ incognito_mode
```

##  Dependencias

- `pandas` - procesamiento de datos
- `numpy` - cÃ¡lculos numÃ©ricos
- `geoip2` - geolocalizaciÃ³n de IPs
- `pyarrow` - soporte Parquet

Ver `requirements.txt` para versiones exactas.

##  Notas

- **Datos locales**: No se versiona `data/` (configurado en `.gitignore`)
- **Debugging**: Ver logs en consola de cada paso del pipeline
- **Manejo de errores**: El script continÃºa si falla la geolocalizaciÃ³n
- **Idempotencia**: Puedes ejecutar `main.py` mÃºltiples veces sin problemas

## ðŸŽ“ PropÃ³sito

Portfolio tÃ©cnico demostrando:
- âœ… IngenierÃ­a de datos (ETL)
- âœ… Modelado dimensional (Star Schema)
- âœ… Limpieza y validaciÃ³n de datos
- âœ… GIS/GeolocalizaciÃ³n
- âœ… Pandas y procesamiento de datos
- âœ… EstructuraciÃ³n de proyectos Python

---

**Ãšltima actualizaciÃ³n**: Feb 2026
